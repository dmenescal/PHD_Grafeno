{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenvolvimento do modelo de SNN para classificar cada imagem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento da base de imagens, junto com os valores esperados (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import snntorch as snn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from snntorch import functional as SF\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import itertools\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file</th>\n",
       "      <th>img_nfi</th>\n",
       "      <th>d0</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>soft_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_0.1i).jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_0.2i).jpg</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.105960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_0.3i).jpg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_0.4i).jpg</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_0.5i).jpg</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.298013</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.026490</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.026490</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_9.6i).jpg</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.178808</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.198675</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_9.7i).jpg</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.178808</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0.205298</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_9.8i).jpg</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.026490</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.178808</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.198675</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_9.9i).jpg</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.192053</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.158940</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>cone_luz_sem_grafeno_n2_(11.6964_+_9i).jpg</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.139073</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         img_file  img_nfi        d0  \\\n",
       "0    cone_luz_sem_grafeno_n2_(11.6964_+_0.1i).jpg      0.1  0.920530   \n",
       "1    cone_luz_sem_grafeno_n2_(11.6964_+_0.2i).jpg      0.2  0.827815   \n",
       "2    cone_luz_sem_grafeno_n2_(11.6964_+_0.3i).jpg      0.3  0.821192   \n",
       "3    cone_luz_sem_grafeno_n2_(11.6964_+_0.4i).jpg      0.4  0.854305   \n",
       "4    cone_luz_sem_grafeno_n2_(11.6964_+_0.5i).jpg      0.5  0.543046   \n",
       "..                                            ...      ...       ...   \n",
       "228  cone_luz_sem_grafeno_n2_(11.6964_+_9.6i).jpg      9.6  0.039735   \n",
       "229  cone_luz_sem_grafeno_n2_(11.6964_+_9.7i).jpg      9.7  0.033113   \n",
       "230  cone_luz_sem_grafeno_n2_(11.6964_+_9.8i).jpg      9.8  0.026490   \n",
       "231  cone_luz_sem_grafeno_n2_(11.6964_+_9.9i).jpg      9.9  0.059603   \n",
       "232    cone_luz_sem_grafeno_n2_(11.6964_+_9i).jpg      9.0  0.072848   \n",
       "\n",
       "           d1        d2        d3        d4        d5        d6        d7  \\\n",
       "0    0.033113  0.006623  0.019868  0.000000  0.000000  0.000000  0.006623   \n",
       "1    0.006623  0.000000  0.006623  0.013245  0.006623  0.006623  0.013245   \n",
       "2    0.006623  0.019868  0.006623  0.000000  0.019868  0.000000  0.006623   \n",
       "3    0.006623  0.013245  0.019868  0.006623  0.000000  0.000000  0.000000   \n",
       "4    0.298013  0.006623  0.026490  0.013245  0.026490  0.006623  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "228  0.039735  0.079470  0.119205  0.178808  0.092715  0.198675  0.165563   \n",
       "229  0.052980  0.072848  0.092715  0.178808  0.072848  0.205298  0.165563   \n",
       "230  0.039735  0.059603  0.119205  0.178808  0.086093  0.198675  0.165563   \n",
       "231  0.039735  0.059603  0.092715  0.192053  0.079470  0.185430  0.158940   \n",
       "232  0.033113  0.066225  0.092715  0.139073  0.112583  0.185430  0.165563   \n",
       "\n",
       "           d8        d9  soft_label  \n",
       "0    0.006623  0.006623           0  \n",
       "1    0.013245  0.105960           0  \n",
       "2    0.006623  0.112583           0  \n",
       "3    0.000000  0.099338           0  \n",
       "4    0.006623  0.072848           0  \n",
       "..        ...       ...         ...  \n",
       "228  0.006623  0.079470           6  \n",
       "229  0.013245  0.112583           6  \n",
       "230  0.006623  0.119205           6  \n",
       "231  0.006623  0.125828           4  \n",
       "232  0.013245  0.119205           6  \n",
       "\n",
       "[233 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_db_dir = 'final_image_database_loss_deciles.csv'\n",
    "\n",
    "img_deciles = pd.read_csv(img_db_dir)\n",
    "img_deciles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção do DataSet de Entrada para pré-processamento.\n",
    "### Ele contém a imagem como uma matriz numérica, junto do perfil de decil (d0-d9) como valor esperado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para adequar ao formato do pytorch, é necessário criar classes para criar o dataset e preprocessamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGuideImageData(Dataset):\n",
    "    def __init__(self, train=True, transform=None):\n",
    "        #Get images directory\n",
    "        img_dir = '../imgs'\n",
    "        images = os.listdir(img_dir)\n",
    "\n",
    "        # Create empty Pandas DataFrame\n",
    "        full_ds_pdf = pd.DataFrame(columns=['feature', 'd0', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9'])\n",
    "\n",
    "        #Load all files into one Pandas Dataframe\n",
    "        for img_file in images:\n",
    "            nova_img = {}\n",
    "            img = cv2.imread('../imgs/'+img_file)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            nova_img['feature'] = img\n",
    "            img_decil_df = img_deciles[img_deciles.img_file == img_file].copy()\n",
    "            nova_img['d0'] = float(img_decil_df.d0)\n",
    "            nova_img['d1'] = float(img_decil_df.d1)\n",
    "            nova_img['d2'] = float(img_decil_df.d2)\n",
    "            nova_img['d3'] = float(img_decil_df.d3)\n",
    "            nova_img['d4'] = float(img_decil_df.d4)\n",
    "            nova_img['d5'] = float(img_decil_df.d5)\n",
    "            nova_img['d6'] = float(img_decil_df.d6)\n",
    "            nova_img['d7'] = float(img_decil_df.d7)\n",
    "            nova_img['d8'] = float(img_decil_df.d8)\n",
    "            nova_img['d9'] = float(img_decil_df.d9)\n",
    "            full_ds_pdf = full_ds_pdf.append(nova_img, ignore_index=True)\n",
    "\n",
    "        #Splitting data into train and validation set\n",
    "        X_train, X_test, y_d0_train, y_d0_test,\\\n",
    "                 y_d1_train, y_d1_test,\\\n",
    "                 y_d2_train, y_d2_test,\\\n",
    "                 y_d3_train, y_d3_test,\\\n",
    "                 y_d4_train, y_d4_test,\\\n",
    "                 y_d5_train, y_d5_test,\\\n",
    "                 y_d6_train, y_d6_test,\\\n",
    "                 y_d7_train, y_d7_test,\\\n",
    "                 y_d8_train, y_d8_test,\\\n",
    "                 y_d9_train, y_d9_test = train_test_split(full_ds_pdf.feature,\n",
    "                                                          full_ds_pdf.d0,\n",
    "                                                          full_ds_pdf.d1,\n",
    "                                                          full_ds_pdf.d2,\n",
    "                                                          full_ds_pdf.d3,\n",
    "                                                          full_ds_pdf.d4,\n",
    "                                                          full_ds_pdf.d5,\n",
    "                                                          full_ds_pdf.d6,\n",
    "                                                          full_ds_pdf.d7,\n",
    "                                                          full_ds_pdf.d8,\n",
    "                                                          full_ds_pdf.d9, test_size=0.2)\n",
    "        if train == True:\n",
    "            self.x = X_train\n",
    "            self.d0_y = y_d0_train\n",
    "            self.d1_y = y_d1_train\n",
    "            self.d2_y = y_d2_train\n",
    "            self.d3_y = y_d3_train\n",
    "            self.d4_y = y_d4_train\n",
    "            self.d5_y = y_d5_train\n",
    "            self.d6_y = y_d6_train\n",
    "            self.d7_y = y_d7_train\n",
    "            self.d8_y = y_d8_train\n",
    "            self.d9_y = y_d9_train\n",
    "        else:\n",
    "            self.x = X_test\n",
    "            self.d0_y = y_d0_test\n",
    "            self.d1_y = y_d1_test\n",
    "            self.d2_y = y_d2_test\n",
    "            self.d3_y = y_d3_test\n",
    "            self.d4_y = y_d4_test\n",
    "            self.d5_y = y_d5_test\n",
    "            self.d6_y = y_d6_test\n",
    "            self.d7_y = y_d7_test\n",
    "            self.d8_y = y_d8_test\n",
    "            self.d9_y = y_d9_test\n",
    "        # Applying Transformation\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(self.x.iloc[idx]).astype('float')\n",
    "        d0 = self.d0_y.iloc[idx].astype('float')\n",
    "        d1 = self.d1_y.iloc[idx].astype('float')\n",
    "        d2 = self.d2_y.iloc[idx].astype('float')\n",
    "        d3 = self.d3_y.iloc[idx].astype('float')\n",
    "        d4 = self.d4_y.iloc[idx].astype('float')\n",
    "        d5 = self.d5_y.iloc[idx].astype('float')\n",
    "        d6 = self.d6_y.iloc[idx].astype('float')\n",
    "        d7 = self.d7_y.iloc[idx].astype('float')\n",
    "        d8 = self.d8_y.iloc[idx].astype('float')\n",
    "        d9 = self.d9_y.iloc[idx].astype('float')\n",
    "\n",
    "        sample={'image':image,\n",
    "                'd0': d0,\n",
    "                'd1': d1,\n",
    "                'd2': d2,\n",
    "                'd3': d3,\n",
    "                'd4': d4,\n",
    "                'd5': d5,\n",
    "                'd6': d6,\n",
    "                'd7': d7,\n",
    "                'd8': d8,\n",
    "                'd9': d9}\n",
    "        # Applying Transformation\n",
    "        if self.transform:\n",
    "            sample = self.transform = sample\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Tamanho da imagem 442 x 442\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Grayscale(), transforms.Normalize((0,),(1,))])\n",
    "\n",
    "train_data = WaveGuideImageData(transform=transform)\n",
    "test_data = WaveGuideImageData(train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=4, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da Arquitetura do modelo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.9 # membrane potential decay rate\n",
    "num_steps = 10 # 10 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\"Simple spiking neural network in snntorch.\"\"\"\n",
    "\n",
    "    def __init__(self, timesteps, hidden, beta):\n",
    "        super().__init__()\n",
    "\n",
    "        self.timesteps = timesteps\n",
    "        self.hidden = hidden\n",
    "        self.beta = beta\n",
    "\n",
    "        # layer 1\n",
    "        self.fc1 = torch.nn.Linear(in_features=586092, out_features=self.hidden)\n",
    "        self.rlif1 = snn.RLeaky(beta=self.beta, V=0.5)\n",
    "\n",
    "        # layer 2\n",
    "        self.fc2 = torch.nn.Linear(in_features=self.hidden, out_features=10)\n",
    "        self.rlif2 = snn.RLeaky(beta=self.beta, V=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass for several time steps.\"\"\"\n",
    "\n",
    "        # Initalize membrane potential\n",
    "        spk1, mem1 = self.rlif1.init_rleaky()\n",
    "        spk2, mem2 = self.rlif2.init_rleaky()\n",
    "\n",
    "        # Empty lists to record outputs\n",
    "        spk_recording = []\n",
    "        for step in range(self.timesteps):\n",
    "            spk1, mem1 = self.rlif1(self.fc1(x.float()), spk1, mem1)\n",
    "            spk2, mem2 = self.rlif2(self.fc2(spk1), spk2, mem2)\n",
    "            spk_recording.append(spk2)\n",
    "\n",
    "        return torch.stack(spk_recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 1024\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = Net(timesteps=num_steps, hidden=hidden, beta=0.9).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição da função erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
    "loss_function = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:09:19<00:00, 831.99s/it, loss=1.134e+00] \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "loss_hist = []\n",
    "\n",
    "with tqdm.trange(num_epochs) as pbar:\n",
    "    for _ in pbar:\n",
    "        train_batch = enumerate(train_loader)\n",
    "        minibatch_counter = 0\n",
    "        loss_epoch = []\n",
    "\n",
    "        for batch_idx, batched_sample in train_batch:\n",
    "            \n",
    "            image = batched_sample['image'].to(device)\n",
    "            d0 = batched_sample['d0'].to(device)\n",
    "            d1 = batched_sample['d1'].to(device)\n",
    "            d2 = batched_sample['d2'].to(device)\n",
    "            d3 = batched_sample['d3'].to(device)\n",
    "            d4 = batched_sample['d4'].to(device)\n",
    "            d5 = batched_sample['d5'].to(device)\n",
    "            d6 = batched_sample['d6'].to(device)\n",
    "            d7 = batched_sample['d7'].to(device)\n",
    "            d8 = batched_sample['d8'].to(device)\n",
    "            d9 = batched_sample['d9'].to(device)\n",
    "            \n",
    "            spk = model(image.flatten(1)) # forward-pass\n",
    "            d0_hat = spk[0]\n",
    "            d1_hat = spk[1]\n",
    "            d2_hat = spk[2]\n",
    "            d3_hat = spk[3]\n",
    "            d4_hat = spk[4]\n",
    "            d5_hat = spk[5]\n",
    "            d6_hat = spk[6]\n",
    "            d7_hat = spk[7]\n",
    "            d8_hat = spk[8]\n",
    "            d9_hat = spk[9]\n",
    "            \n",
    "            loss_val0 = loss_function(d0_hat, d0) # apply loss\n",
    "            loss_val1 = loss_function(d1_hat, d1) # apply loss\n",
    "            loss_val2 = loss_function(d2_hat, d2) # apply loss\n",
    "            loss_val3 = loss_function(d3_hat, d3) # apply loss\n",
    "            loss_val4 = loss_function(d4_hat, d4) # apply loss\n",
    "            loss_val5 = loss_function(d5_hat, d5) # apply loss\n",
    "            loss_val6 = loss_function(d6_hat, d6) # apply loss\n",
    "            loss_val7 = loss_function(d7_hat, d7) # apply loss\n",
    "            loss_val8 = loss_function(d8_hat, d8) # apply loss\n",
    "            loss_val9 = loss_function(d9_hat, d9) # apply loss\n",
    "            \n",
    "            loss = (loss_val0+loss_val1+loss_val2+loss_val3+loss_val4+loss_val5+loss_val6+loss_val7+loss_val8+loss_val9)/10\n",
    "\n",
    "            optimizer.zero_grad() # zero out gradients\n",
    "            loss.backward() # calculate gradients\n",
    "            optimizer.step() # update weights\n",
    "\n",
    "            loss_hist.append(loss.item())\n",
    "            minibatch_counter += 1\n",
    "\n",
    "            avg_batch_loss = sum(loss_hist) / minibatch_counter\n",
    "            pbar.set_postfix(loss=\"%.3e\" % avg_batch_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total accuracy on the test set is: 7.73%\n"
     ]
    }
   ],
   "source": [
    "test_batch = enumerate(test_loader)\n",
    "minibatch_counter = 0\n",
    "loss_epoch = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  total = 0\n",
    "  acc = 0\n",
    "  for batch_idx, batched_sample in test_batch:\n",
    "        \n",
    "      image = batched_sample['image'].to(device)\n",
    "      d0 = batched_sample['d0'].to(device)\n",
    "      d1 = batched_sample['d1'].to(device)\n",
    "      d2 = batched_sample['d2'].to(device)\n",
    "      d3 = batched_sample['d3'].to(device)\n",
    "      d4 = batched_sample['d4'].to(device)\n",
    "      d5 = batched_sample['d5'].to(device)\n",
    "      d6 = batched_sample['d6'].to(device)\n",
    "      d7 = batched_sample['d7'].to(device)\n",
    "      d8 = batched_sample['d8'].to(device)\n",
    "      d9 = batched_sample['d9'].to(device)\n",
    "\n",
    "      spk = model(image.flatten(1)) # forward-pass\n",
    "      \n",
    "      \n",
    "      acc += SF.accuracy_rate(spk, d0) * spk[0].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d1) * spk[1].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d2) * spk[2].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d3) * spk[3].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d4) * spk[4].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d5) * spk[5].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d6) * spk[6].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d7) * spk[7].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d8) * spk[8].size(1)\n",
    "      acc += SF.accuracy_rate(spk, d9) * spk[9].size(1)\n",
    "\n",
    "      total += spk[0].size(1)\n",
    "      total += spk[1].size(1)\n",
    "      total += spk[2].size(1)\n",
    "      total += spk[3].size(1)\n",
    "      total += spk[4].size(1)\n",
    "      total += spk[5].size(1)\n",
    "      total += spk[6].size(1)\n",
    "      total += spk[7].size(1)\n",
    "      total += spk[8].size(1)\n",
    "      total += spk[9].size(1)\n",
    "\n",
    "print(f\"The total accuracy on the test set is: {(acc/total) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn-pso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1e70f11dca2dc5513a0c6b4fc2ed39d02d5fbfdc883f5701900c44d230e79da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
